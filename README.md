# asammdf Agent

**Autonomous GUI Automation Agent with Human-in-the-Loop** - Natural language ‚Üí GUI control with KB-attached learning, verified skills, and iterative improvement.

---

## üöÄ Quick Start

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

# With interactive mode (default) - Press ESC anytime during execution for feedback
result = execute_autonomous_task(
    "Concatenate all MF4 files in C:\\data and save as output.mf4",
    interactive_mode=True  # HITL enabled by default
)
print(f"Success: {result['success']}")
```

**üí° Interactive Mode**: Press **ESC anytime** during execution to provide feedback on the current/completed step.

**On failure:** Agent attaches learning to KB, user reruns for improved plan.
**On success:** Human can verify and save as reusable skill.

---

## üìã Table of Contents

- [System Architecture](#system-architecture)
- [Core Tech Stack](#core-tech-stack)
- [Key Features](#key-features)
- [How It Works](#how-it-works)
- [Folder Structure](#folder-structure)
- [Setup](#setup)
- [Usage Examples](#usage-examples)
- [Performance](#performance)

---

## üèóÔ∏è System Architecture

### KB-Attached Learning with HITL and Iterative Rerun

```
Natural Language Task
    ‚Üì
Skill Matching (HITL) ‚Üí Check verified skills library (fuzzy matching)
    ‚Üì (if no match)
RAG Retrieval (ChromaDB) ‚Üí KB items with past learnings & trust scores
    ‚Üì
AI Planning (GPT-5-mini) ‚Üí Plan with kb_source attribution
    ‚Üì
Adaptive Execution (GPT-4o-mini) ‚Üí Resolve UI elements
    ‚îú‚îÄ Low Confidence ‚Üí Request Human Approval (HITL)
    ‚îú‚îÄ [ANYTIME] Press ESC ‚Üí Provide Feedback on Current/Completed Step (HITL) ‚å®Ô∏è
    ‚Üì
On Failure: Attach learning ‚Üí Stop ‚Üí User reruns with improved context
On Success: Human Verification ‚Üí Save as Verified Skill (HITL)
```

**Key HITL Feature**: The **ESC key works anytime during execution** - press it while the agent is working, and feedback will be requested as soon as the current step completes. Non-blocking and seamless.

### Core Principles

1. **KB-Attached Learning**: Learnings stored WITH the KB items they correct
2. **Human-in-the-Loop**: Skills library, action approval, interactive feedback, task verification
3. **Iterative Rerun**: Execution stops on failure, user explicitly reruns
4. **Dynamic Enrichment**: Related docs retrieved fresh during each planning
5. **Vector Consistency**: Catalog is single source of truth
6. **Learning Prioritization**: Verified skills > Learnings > Documentation

---

## üíª Core Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Knowledge Base** | ChromaDB + sentence-transformers | Semantic doc search with metadata |
| **Planning** | GPT-5-mini (OpenAI) | Generate tool sequences with kb_source attribution |
| **Execution** | GPT-4o-mini (OpenAI) | Dynamic UI element resolution |
| **Learning Storage** | JSON catalog + ChromaDB metadata | KB-attached learnings with trust scores |
| **Skills Library** | JSON per task | Human-verified workflows with fuzzy matching |
| **HITL Observer** | Background thread | Non-blocking human approvals/feedback |
| **Orchestration** | LangGraph | 6-node state machine (no automatic replanning) |
| **MCP Tools** | Windows-MCP server | 13+ GUI automation tools |
| **Keyboard Listener** | pynput | ESC key for interactive feedback |

**Note**: Fully self-contained system using JSON storage (no external databases required).

---

## ‚ú® Key Features

### Human-in-the-Loop (HITL) System
‚úÖ **Verified Skills Library** - Save successful workflows, reuse with fuzzy matching (‚â•70% similarity)
‚úÖ **Interactive Mode** - Press ESC anytime during execution for step feedback
‚úÖ **Low-Confidence Approval** - System requests human approval for uncertain actions (<50% confidence)
‚úÖ **Task Verification** - Human verifies completion and optionally saves as skill
‚úÖ **Focus Management** - Auto-switches back to target app after terminal interaction

### KB-Attached Learning System
‚úÖ **Learnings live with KB items** - Errors attached to the KB patterns that caused them
‚úÖ **Trust score tracking** - KB items decay by 0.95 per failure (min 0.5)
‚úÖ **kb_source attribution** - LLM sets which KB item inspired each action
‚úÖ **Dynamic doc retrieval** - Related docs retrieved fresh during planning (not stored)
‚úÖ **Vector metadata sync** - Catalog is single source of truth, metadata reloaded automatically

### Iterative Rerun Architecture
‚úÖ **No automatic replanning** - Execution stops on failure, user controls reruns
‚úÖ **Progressive improvement** - Each rerun sees more learnings, generates better plans
‚úÖ **Deterministic flow** - Simple, predictable, debuggable
‚úÖ **User control** - Explicit reruns, clear feedback

### Planning & Execution
‚úÖ **Documentation-driven** - GPT extracts knowledge from docs (no hardcoding)
‚úÖ **Adaptive resolution** - Resolves UI elements dynamically with GPT-4o-mini
‚úÖ **Learning prioritization** - Verified skills > Learnings > Documentation
‚úÖ **Prompt history** - Every planning prompt saved for debugging
‚úÖ **Cost tracking** - Real-time API monitoring by component/model
‚úÖ **State caching** - Reuses UI state across actions in same step

---

## üîÑ How It Works

### Example: "Concatenate MF4 files"

#### First Run (Failure)

**1. RAG Retrieval** (<1s)
```
Query: "Concatenate MF4 files"
Retrieved 5 KB items: concatenate_files, open_files, save_file, ...
  ‚Ä¢ open_files (trust: 1.0, learnings: 0)
```

**2. Planning** (2-5s)
```
LLM generates plan with kb_source attribution:
Step 5: Click "Add Files" button
  - kb_source: "open_files"  ‚Üê LLM sets this
  - reasoning: "Open files using Add Files button"
```

**3. Execution** (~500ms/step)
```
Step 1-4: ‚úì Success
Step 5: ‚úó FAILURE - "Button 'Add Files' not found"
```

**4. Failure Handling**
```
Create FailureLearning:
  - task: "Concatenate MF4 files"
  - step_num: 5
  - original_action: {"tool_name": "Click-Tool", ...}
  - original_error: "Button 'Add Files' not found"
  - recovery_approach: ""  (empty until success)

Attach to KB item "open_files":
  - kb_learnings: [<learning>]
  - trust_score: 0.95  (decreased from 1.0)

Update vector metadata:
  - has_learnings: true
  - learning_count: 1

STOP EXECUTION
Message: "Learning attached to KB. Please rerun the task."
```

**Catalog After First Run:**
```json
{
  "knowledge_id": "open_files",
  "kb_learnings": [
    {
      "task": "Concatenate MF4 files",
      "original_error": "Button 'Add Files' not found",
      "recovery_approach": ""
    }
  ],
  "trust_score": 0.95
}
```

#### First Rerun (Success)

**1. RAG Retrieval** (<1s)
```
Retrieved KB "open_files" WITH learning:
  ‚Ä¢ trust: 0.95
  ‚Ä¢ learnings: 1 (Button 'Add Files' failed)
```

**2. Planning with Learning Context** (2-5s)
```
_format_kb_with_learnings() formats:

---
KB ID: open_files
Description: Open files in asammdf
Action Sequence: click_menu('File'), select_option('Open')
---

‚ö†Ô∏è PAST LEARNINGS (1 correction):

1. Past Failure:
   - Failed Action: Click-Tool
   - Error: Button 'Add Files' not found
   - Successful Approach: (Not yet resolved - see related docs below)

   üìö Related Docs (2):  ‚Üê Retrieved dynamically
      ‚Ä¢ KB ID: file_menu_open
        Open files using File ‚Üí Open menu
        Shortcut: Ctrl+O
        Actions: click_menu('File'), select_option('Open')

      ‚Ä¢ KB ID: keyboard_shortcuts
        Use keyboard shortcuts for faster navigation
        Actions: press_keys('Ctrl+O')

‚ö†Ô∏è CAUTION: Trust score 0.95 (has 1 known issue)
---

CRITICAL RULE in system prompt:
"DO NOT repeat failed actions even if multiple KB items suggest them.
Learnings trump documentation."
```

**3. Planning Result**
```
LLM sees:
  ‚úó Learning: "Add Files" button failed
  ‚úì Related docs: Use Ctrl+O or File ‚Üí Open menu
  ‚úì Critical rule: Don't repeat failures

Generated plan:
Step 5: Press Ctrl+O to open file dialog  ‚Üê Changed!
  - kb_source: "keyboard_shortcuts"
  - reasoning: "Use shortcut instead of button (learning shows button failed)"
```

**4. Execution** (~500ms/step)
```
Step 1-5: ‚úì All success (including fixed step 5)
Step 6-10: ‚úì All success

EXECUTION COMPLETE ‚úì
```

#### Next Similar Task

```
User runs: "Concatenate MF4 files in D:\folder"

RAG retrieves "open_files" with learning ‚Üí LLM sees failure context
‚Üí Generates correct plan immediately (uses Ctrl+O)
‚Üí Success on first try
```

---

## üìÅ Folder Structure

```
agent/
‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îî‚îÄ‚îÄ autonomous_workflow.py      # LangGraph orchestrator (6-node + HITL)
‚îú‚îÄ‚îÄ knowledge_base/                 # RAG System
‚îÇ   ‚îú‚îÄ‚îÄ doc_parser.py               # Parse documentation with GPT
‚îÇ   ‚îú‚îÄ‚îÄ indexer.py                  # Index into ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py                # Semantic search + metadata updates
‚îÇ   ‚îú‚îÄ‚îÄ parsed_knowledge/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ knowledge_catalog.json  # SOURCE OF TRUTH (learnings stored here)
‚îÇ   ‚îî‚îÄ‚îÄ vector_store/               # ChromaDB (metadata synced from catalog)
‚îú‚îÄ‚îÄ planning/                       # Planning System
‚îÇ   ‚îú‚îÄ‚îÄ workflow_planner.py         # GPT-5-mini planning with learning formatting
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                  # KnowledgeSchema, ActionSchema, FailureLearning
‚îÇ   ‚îî‚îÄ‚îÄ plans/                      # Cached plans (Plan_0, Plan_1, ...)
‚îú‚îÄ‚îÄ execution/                      # Execution System
‚îÇ   ‚îú‚îÄ‚îÄ mcp_client.py               # MCP protocol (async)
‚îÇ   ‚îî‚îÄ‚îÄ adaptive_executor.py        # GPT-4o-mini resolution + failure handling
‚îú‚îÄ‚îÄ feedback/                       # HITL System
‚îÇ   ‚îú‚îÄ‚îÄ human_observer.py           # Background thread for approvals/feedback
‚îÇ   ‚îú‚îÄ‚îÄ communication_protocol.py   # Message passing protocol
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                  # FailureLearning, HumanFeedback, Verification
‚îú‚îÄ‚îÄ learning/                       # Skills Library
‚îÇ   ‚îú‚îÄ‚îÄ skill_library.py            # Verified workflows storage & matching
‚îÇ   ‚îî‚îÄ‚îÄ verified_skills/            # Task-specific skill JSON files
‚îú‚îÄ‚îÄ prompts/                        # Centralized LLM prompts
‚îÇ   ‚îú‚îÄ‚îÄ planning_prompt.py          # System/user prompts + history saving
‚îÇ   ‚îú‚îÄ‚îÄ coordinate_resolution_prompt.py
‚îÇ   ‚îî‚îÄ‚îÄ planning_history/           # Saved prompts (Plan_0.md, Plan_1.md, ...)
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ cost_tracker.py             # API cost monitoring
```

---

## üõ†Ô∏è Setup

### 1. Install Dependencies

```bash
# Create virtual environment
python -m venv .agent-venv
.agent-venv\Scripts\activate
pip install -r requirements.txt

# Install Windows-MCP tools
cd tools\Windows-MCP
python -m venv .windows-venv
.windows-venv\Scripts\activate
pip install -e .
cd ..\..
```

### 2. Configure API Key

```bash
cp .env.example .env
# Edit .env: OPENAI_API_KEY=sk-...
```

### 3. Build Knowledge Base (one-time)

```bash
# Parse documentation
python agent/knowledge_base/doc_parser.py

# Build vector index
python agent/knowledge_base/indexer.py --rebuild
```

### 4. Run

```bash
python agent/workflows/autonomous_workflow.py "Your task here"
```

---

## üìñ Usage Examples

### Basic Usage

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

result = execute_autonomous_task("Open sample.mf4 and plot first signal")
print(f"Success: {result['success']}")
```

### Handling Failures (Iterative Rerun)

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

# First attempt - may fail
result = execute_autonomous_task("Concatenate all MF4 files")

if not result['success']:
    print("Failure detected. Learning attached to KB.")
    print("Rerunning with improved context...")

    # Rerun - agent sees learning + related docs
    result = execute_autonomous_task("Concatenate all MF4 files")
    print(f"Second attempt: {result['success']}")
```

### Custom Configuration

```python
from agent.workflows.autonomous_workflow import AutonomousWorkflow

workflow = AutonomousWorkflow(
    app_name="asammdf 8.6.10",
    catalog_path="agent/knowledge_base/parsed_knowledge/knowledge_catalog.json",
    vector_db_path="agent/knowledge_base/vector_store",
    max_retries=0  # No automatic retries (user-controlled reruns)
)
result = workflow.run_sync("Your task")
```

### Cost Tracking

```python
from agent.utils.cost_tracker import get_global_tracker

tracker = get_global_tracker()
tracker.print_summary()  # Component/model breakdown
tracker.save_to_file()   # Export to cost_reports/
```

### Inspect KB Learnings

```python
from agent.knowledge_base import KnowledgeRetriever

retriever = KnowledgeRetriever()

# Get specific KB item
kb_item = retriever.get_by_id("open_files")
print(f"Trust score: {kb_item.trust_score}")
print(f"Learnings: {len(kb_item.kb_learnings)}")

for learning in kb_item.kb_learnings:
    print(f"Error: {learning['original_error']}")
    print(f"Recovery: {learning['recovery_approach']}")
```

### Inspect Prompt History

```bash
# View planning prompts
ls agent/prompts/planning_history/

# Example files:
Concatenate_files_Plan_0.md  # First attempt (no learnings)
Concatenate_files_Plan_1.md  # First rerun (with learnings + related docs)
Concatenate_files_Plan_2.md  # Second rerun (with more learnings)
```

### Rebuild KB Index After Manual Edits

```python
from agent.knowledge_base.indexer import rebuild_index

# Rebuild entire index from catalog
rebuild_index(catalog_path="agent/knowledge_base/parsed_knowledge/knowledge_catalog.json")
```

---

## ‚ö° Performance

### Typical Task (First Run - No Learnings)
- Knowledge retrieval: <1s
- Plan generation: 2-5s
- Execution: 10-60s (task-dependent)
- Success rate: 70-80%

### After Learning (Rerun with Context)
- Knowledge retrieval: <1s (includes learnings)
- Plan generation: 2-5s (improved with learning context)
- Execution: 10-60s
- Success rate: 85-95%

### Subsequent Similar Tasks
- Uses existing learnings from first encounter
- Success rate: 95%+

---

## üìä Data Storage

### Knowledge Base Catalog (Single Source of Truth)
```
agent/knowledge_base/parsed_knowledge/
‚îî‚îÄ‚îÄ knowledge_catalog.json     # All KB items + learnings + trust scores
```

### Vector Store (Synced Metadata)
```
agent/knowledge_base/vector_store/
‚îî‚îÄ‚îÄ ChromaDB files              # Full KnowledgeSchema + convenience fields
                                # (has_learnings, learning_count, trust_score)
```

### Cached Plans
```
agent/planning/plans/
‚îú‚îÄ‚îÄ Concatenate_files_Plan_0.json
‚îú‚îÄ‚îÄ Concatenate_files_Plan_1.json  # Incremental plan after first rerun
‚îî‚îÄ‚îÄ Open_plot_data_Plan_0.json
```

### Prompt History (Debugging)
```
agent/prompts/planning_history/
‚îú‚îÄ‚îÄ Concatenate_files_Plan_0.md    # Full system + user prompts
‚îî‚îÄ‚îÄ Concatenate_files_Plan_1.md    # Shows learnings + related docs
```

---

## ü§ù Human-in-the-Loop (HITL) Features

The system provides **four levels of human involvement**:

### 1. Verified Skills Library (Highest Priority)

**What**: Reuse proven workflows for similar tasks
**When**: Before planning phase
**How**:
```python
# After successful task completion
workflow = AutonomousWorkflow(enable_hitl=True)
result = workflow.run_sync("Concatenate MF4 files in folder X")

# Human verifies ‚Üí System prompts to save as skill
# Next similar task: "Concatenate MF4 files in folder Y"
# ‚Üí Skill matched (75%+ similarity) ‚Üí Reuses proven plan
```

**Benefits**:
- Skip planning entirely for known tasks
- Fuzzy matching finds similar tasks (‚â•70% similarity threshold)
- Tracks success rate, times used
- Each task type has its own skills file (e.g., `concatenate_mf4_files_skills.json`)

### 2. Low-Confidence Action Approval

**What**: Human approval for uncertain actions
**When**: Before executing action with confidence < 50%
**How**:
```
[Confidence: 0.45] About to: Click button at [450, 300]
Approve? [y/n/correct]:
  y ‚Üí Execute as planned
  n ‚Üí Skip action
  correct ‚Üí Provide corrected action
```

**Confidence factors**:
- Tool type (State-Tool: low risk, Click-Tool: high risk)
- Has symbolic references (e.g., `['last_state:button:Save']`)
- Number of recent failures
- KB item trust score

### 3. Interactive Mode (ESC Key Feedback) ‚å®Ô∏è

**What**: Press ESC **anytime during execution** to provide feedback on current/completed step
**When**: Works at any moment - while agent is planning, executing, or between steps
**How**:
```bash
python agent/workflows/autonomous_workflow.py "Your task" --interactive true

# During execution - Press ESC ANYTIME:
[Step 3/10] Executing...
[ESC pressed] ‚Üê You press ESC while step is running
[ESC pressed] Feedback will be requested after current step completes...
[Step 3/10] ‚úì Success
[Step 4/10] ‚úì Success

[Interactive] Step 4 completed
Provide feedback for this step? [y/N/stop]: y
  1. Was the action correct? [y/n]: n
  2. What should have been done? (describe): Use Ctrl+S instead of clicking Save
  3. Why? (reasoning): Save button location changes in different views
‚úì Feedback recorded
```

**Benefits**:
- **Anytime interrupt** - Press ESC whenever you notice something wrong
- **Non-blocking** - Doesn't interrupt current action, waits for safe completion point
- **Keyboard listener** - Monitors ESC key continuously in background
- **Focus auto-switched** - Returns to target app after feedback
- **KB learning** - Creates learning entry attached to KB item

### 4. Final Task Verification

**What**: Human verifies task completed successfully
**When**: After all steps complete
**How**:
```
[HITL] Final Verification
Task completed all 10 steps. Did it succeed? [y/n/partial]: y
Want to save as verified skill? [y/n]: y
  Tags (comma-separated, optional): mf4,concatenate,file_operations
‚úì Created verified skill: skill_001_20250126_143000
```

**Benefits**:
- Ensures task actually succeeded (not just "no errors")
- Creates reusable verified skill
- Tracks human feedbacks & agent recoveries in metadata

---

## üéØ What Makes This Special

### 1. KB-Attached Learning
- **Errors live with patterns**: Learning attached to the KB item that caused the failure
- **Automatic attribution**: LLM sets `kb_source` field, system tracks which patterns fail
- **Trust scores**: KB items decay with failures (0.95 per failure, min 0.5)
- **Contextual retrieval**: Low-trust KB items appear with warning labels

### 2. Dynamic Doc Enrichment
- **Fresh retrieval**: Related docs retrieved during each planning phase (not stored statically)
- **Adapts to changes**: If KB improves, related docs reflect latest state
- **Minimal storage**: Learnings store only error + recovery (not 3 related docs)

### 3. Iterative Rerun (Not Automatic Replanning)
- **User control**: Explicit reruns, no hidden retry loops
- **Deterministic**: Predictable flow, easy to debug
- **Progressive**: Each rerun builds on previous learnings
- **Simple code**: ~155 lines removed vs. automatic replanning

### 4. Learning Prioritization
- **Explicit rule**: "Learnings trump documentation"
- **Prevents circular failures**: Won't repeat failed action even if 10 KB docs suggest it
- **Real-world evidence**: 1 failure learning > N docs (learnings show actual execution results)

### 5. Vector Metadata Consistency
- **Catalog as source of truth**: Vector metadata reloaded from catalog on every update
- **No drift**: Impossible for metadata to become stale
- **Simple API**: `update_vector_metadata(kb_id)` - everything else automatic

### 6. Prompt History
- **Full debugging visibility**: Every planning prompt saved with KB items + learnings
- **Compare iterations**: Plan_0 (no learnings) vs Plan_1 (with learnings)
- **Reproducibility**: See exact LLM input for any planning phase

---

## üèóÔ∏è Architecture Diagrams

### KB-Attached Learning Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  knowledge_catalog.json (SOURCE OF TRUTH)                   ‚îÇ
‚îÇ  {                                                           ‚îÇ
‚îÇ    "knowledge_id": "open_files",                            ‚îÇ
‚îÇ    "kb_learnings": [                                        ‚îÇ
‚îÇ      {                                                       ‚îÇ
‚îÇ        "original_error": "Button not found",                ‚îÇ
‚îÇ        "recovery_approach": "Use Ctrl+O"                    ‚îÇ
‚îÇ      }                                                       ‚îÇ
‚îÇ    ],                                                        ‚îÇ
‚îÇ    "trust_score": 0.95                                      ‚îÇ
‚îÇ  }                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì (synced on update)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ChromaDB Vector Metadata                                   ‚îÇ
‚îÇ  {                                                           ‚îÇ
‚îÇ    "full_knowledge": "{...entire KnowledgeSchema JSON...}", ‚îÇ
‚îÇ    "knowledge_id": "open_files",                            ‚îÇ
‚îÇ    "has_learnings": true,                                   ‚îÇ
‚îÇ    "learning_count": 1,                                     ‚îÇ
‚îÇ    "trust_score": 0.95                                      ‚îÇ
‚îÇ  }                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Iterative Rerun Flow

```
First Run:
  Retrieve KB ‚Üí Plan ‚Üí Execute ‚Üí FAILURE
                                    ‚Üì
                          Create FailureLearning
                                    ‚Üì
                          Attach to KB item (via kb_source)
                                    ‚Üì
                          Update trust_score (0.95)
                                    ‚Üì
                          Update vector metadata
                                    ‚Üì
                          STOP EXECUTION
                          "Please rerun the task"

First Rerun:
  Retrieve KB (with learning) ‚Üí Format with learning context
                                    ‚Üì
                          Dynamically retrieve related docs
                                    ‚Üì
                          Plan with learning + docs + CRITICAL rule
                                    ‚Üì
                          Execute ‚Üí SUCCESS
```

---

## üîß Key Configuration Options

### Workflow Configuration

```python
workflow = AutonomousWorkflow(
    app_name="asammdf 8.6.10",              # Target app
    catalog_path="...",                      # KB catalog location
    vector_db_path="...",                    # ChromaDB location
    max_retries=0,                           # No automatic retries (user reruns)
    enable_hitl=False,                       # HITL disabled by default in current version
    session_id="user_123"                    # Session tracking (optional)
)
```

### Planning Configuration

- **Model**: GPT-4o (`gpt-4o-2024-11-20`)
- **Temperature**: Default (0.7)
- **Max tokens**: 120,000
- **Timeout**: 600s

### Execution Configuration

- **Model**: GPT-4o-mini
- **Temperature**: Default (0.7)
- **Timeout**: 60s

---

## üìù Schemas Reference

### KnowledgeSchema

```python
class KnowledgeSchema(BaseModel):
    knowledge_id: str                    # Unique identifier
    description: str                     # What this KB item does
    ui_location: str                     # Where to find it in UI
    action_sequence: List[str]           # Step-by-step actions
    shortcut: Optional[str] = None       # Keyboard shortcut
    kb_learnings: List[Dict] = []        # Attached learnings
    trust_score: float = 1.0             # Reliability score
```

### ActionSchema

```python
class ActionSchema(BaseModel):
    tool_name: str                       # MCP tool to use
    tool_arguments: Dict[str, Any]       # Tool arguments
    reasoning: str                       # Why this action
    kb_source: Optional[str] = None      # Which KB item inspired this (LLM sets)
```

### FailureLearning

```python
class FailureLearning(BaseModel):
    task: str                            # Task being executed
    step_num: int                        # Which step failed
    original_action: Dict[str, Any]      # Action that failed
    original_error: str                  # Error message
    recovery_approach: str = ""          # How it was fixed (empty until success)
    timestamp: str                       # When failure occurred
    # NO related_docs field (retrieved dynamically)
```

---

## ‚ö†Ô∏è Limitations

- **Platform:** Windows-only (Windows UI Automation)
- **Scope:** Single application (designed for asammdf)
- **Vision:** Text-based UI state (no GPT-4o vision currently)
- **Execution:** Sequential (no parallel actions)
- **Learning:** User must explicitly rerun to apply learnings

---

## üöß Design Decisions & Trade-offs

### ‚úÖ What's Included

1. **HITL System** - Fully integrated (skills library, approvals, interactive mode, verification)
2. **KB-Attached Learning** - Learnings stored with KB items (not separate memory)
3. **Iterative Rerun** - User-controlled reruns (no automatic replanning)
4. **JSON Storage** - Self-contained, no external databases
5. **Two-Model Approach** - GPT-5-mini for planning, GPT-4o-mini for resolution
6. **Task-Specific Skills** - Each task type has its own skills file

### ‚ùå What's Excluded

- ‚ùå **Mem0 integration** - Code scaffolding exists but disabled (using JSON only)
- ‚ùå **Automatic replanning** - Removed in favor of explicit user reruns
- ‚ùå **Multi-attempt retries** - Disabled (max_retries=0, user reruns instead)
- ‚ùå **Vision-based state** - Text-only UI state (no GPT-4o vision yet)
- ‚ùå **Parallel execution** - Sequential only (one action at a time)
- ‚ùå **Multi-app workflows** - Single application focus

---

## ü§ù Contributing

Key design principles:

1. **Catalog is truth** - All learnings in `knowledge_catalog.json`
2. **User-controlled reruns** - No automatic replanning
3. **Dynamic retrieval** - Related docs fetched fresh, never stored
4. **Type safety** - Pydantic everywhere
5. **Centralized prompts** - All in `agent/prompts/` for easy A/B testing
6. **Prompt history** - Save every planning prompt for debugging

---

## üìà Status

**Current Version:** KB-Attached Learning with Full HITL Integration

‚úÖ **Complete:**
- ‚úÖ HITL System (skills library, action approval, interactive mode, task verification)
- ‚úÖ KB-attached learning system
- ‚úÖ Iterative rerun architecture (no automatic replanning)
- ‚úÖ Dynamic doc enrichment (related docs retrieved during planning)
- ‚úÖ Vector metadata consistency (catalog as source of truth)
- ‚úÖ Learning prioritization (skills > learnings > docs)
- ‚úÖ Prompt history saving (debugging visibility)
- ‚úÖ Trust score tracking
- ‚úÖ Cost monitoring
- ‚úÖ Task-specific skill files
- ‚úÖ Focus management after feedback
- ‚úÖ Keyboard listener (ESC key)

üöß **Future Enhancements:**
- Multi-app workflows
- GPT-4o vision integration for state capture
- Parallel action execution
- Automatic skill discovery from execution patterns

---

## üìù License

[Specify your license here]

---

**Happy Automating! üöÄ**

For questions or issues:
- Code documentation (inline comments and docstrings)
- Prompt history (`agent/prompts/planning_history/`)
- KB catalog (`agent/knowledge_base/parsed_knowledge/knowledge_catalog.json`)
