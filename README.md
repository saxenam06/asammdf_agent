# asammdf Agent

**Autonomous GUI Automation Agent with Human-in-the-Loop** - Natural language â†’ GUI control with KB-attached learning, verified skills, and LLM-generated recovery approaches.

---

## ğŸš€ Quick Start

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

# With interactive mode - Press ESC anytime during execution for feedback
result = execute_autonomous_task(
    "Concatenate all MF4 files in C:\\data and save as output.mf4",
    interactive_mode=True  # HITL enabled
)
print(f"Success: {result['success']}")
```

**ğŸ’¡ Interactive Mode**: Press **ESC anytime** during execution to provide feedback.

**On failure:** Agent attaches learning to KB â†’ user reruns with improved context
**On success:** Human verifies â†’ save as reusable skill â†’ generate recovery approaches for KB errors

---

## ğŸ—ï¸ System Architecture

```
Natural Language Task
    â†“
[1] Skill Matching â†’ Check verified skills library (fuzzy match â‰¥70%)
    â†“ (if no match)
[2] RAG Retrieval â†’ KB items with learnings, trust scores & recovery approaches
    â†“
[3] Planning (GPT-5-mini) â†’ Generate plan with kb_source attribution
    â†“
[4] Execution (GPT-4o-mini) â†’ Resolve UI elements dynamically
    â”œâ”€ Low Confidence â†’ Request Human Approval
    â”œâ”€ [ESC Key] â†’ Provide Feedback âŒ¨ï¸
    â†“
[5] On Failure â†’ Attach learning â†’ STOP â†’ User reruns
[6] On Success â†’ Human Verification â†’ Save Skill â†’ Generate Recovery Approaches (GPT-4o-mini)
```

### Core Principles

1. **KB-Attached Learning**: Learnings stored WITH KB items that caused failures
2. **Human-in-the-Loop**: Verified skills, approvals, interactive feedback, verification
3. **Iterative Rerun**: Execution stops on failure, user explicitly reruns
4. **Recovery Approaches**: LLM analyzes verified skills to generate actionable recovery guidance
5. **Trust Scores**: KB items decay with failures (0.95Ã— per failure, min 0.5)

---

## ğŸ’» Core Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Knowledge Base** | ChromaDB + sentence-transformers | Semantic doc search |
| **Planning** | GPT-5-mini | Generate action plans |
| **Execution** | GPT-4o-mini | UI element resolution |
| **Recovery Generation** | GPT-4o-mini | Extract learnings from verified skills |
| **Learning Storage** | JSON catalog + ChromaDB | KB-attached learnings |
| **Skills Library** | JSON per task | Human-verified workflows |
| **Orchestration** | LangGraph | 6-node state machine |

---

## âœ¨ Key Features

### 1. Human-in-the-Loop (HITL)
- **Verified Skills** - Save successful workflows, reuse with fuzzy matching
- **Interactive Mode** - Press ESC anytime for step feedback
- **Low-Confidence Approval** - Human approval for uncertain actions
- **Task Verification** - Human verifies completion & saves as skill

### 2. KB-Attached Learning
- **Learnings with KB items** - Errors attached to patterns that caused them
- **Trust score tracking** - KB items decay with failures
- **kb_source attribution** - LLM tracks which KB inspired each action
- **Recovery approaches** - LLM-generated from verified skills

### 3. Iterative Rerun Architecture
- **No automatic replanning** - User controls reruns
- **Progressive improvement** - Each rerun sees more learnings
- **Deterministic flow** - Simple, predictable, debuggable

---

## ğŸ”„ How It Works

### Example: "Concatenate MF4 files"

#### First Run (Failure)
1. **RAG Retrieval**: Get KB item "open_files" (trust: 1.0, learnings: 0)
2. **Planning**: Generate plan â†’ Step 5: Click "Add Files" button (kb_source: "open_files")
3. **Execution**: Steps 1-4 âœ“ | Step 5 âœ— "Button 'Add Files' not found"
4. **Failure Handling**:
   - Create FailureLearning attached to "open_files"
   - Update trust_score: 0.95
   - STOP execution

#### First Rerun (Success)
1. **RAG Retrieval**: Get "open_files" WITH learning (trust: 0.95)
2. **Planning**: LLM sees past failure â†’ generates better plan â†’ Step 5: Press Ctrl+O
3. **Execution**: All steps âœ“ SUCCESS

#### Human Verification & Recovery Generation
1. **Verification**: Human confirms success â†’ saves as verified skill
2. **Recovery Prompt**: "Update knowledge catalog? [y/N]"
3. **LLM Analysis**: GPT-4o-mini analyzes verified skill â†’ generates recovery approaches
4. **KB Update**: Adds `recovery_approach` to learnings with `original_error`

```json
{
  "knowledge_id": "open_files",
  "kb_learnings": [{
    "original_error": "Button 'Add Files' not found",
    "recovery_approach": "Use Ctrl+O or Fileâ†’Open menu instead of looking for Add Files button"
  }],
  "trust_score": 0.95
}
```

---

## ğŸ“ Folder Structure

```
agent/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ autonomous_workflow.py      # LangGraph orchestrator (6 nodes + HITL)
â”œâ”€â”€ knowledge_base/                 # RAG System
â”‚   â”œâ”€â”€ retriever.py                # Semantic search + metadata updates
â”‚   â”œâ”€â”€ recovery_approach_generator.py  # LLM-based recovery generation
â”‚   â”œâ”€â”€ parsed_knowledge/
â”‚   â”‚   â””â”€â”€ knowledge_catalog.json  # SOURCE OF TRUTH (learnings + recovery approaches)
â”‚   â””â”€â”€ vector_store/               # ChromaDB (metadata synced from catalog)
â”œâ”€â”€ planning/                       # Planning System
â”‚   â”œâ”€â”€ workflow_planner.py         # GPT-5-mini planning with learnings
â”‚   â”œâ”€â”€ schemas.py                  # KnowledgeSchema, ActionSchema, PlanSchema
â”‚   â””â”€â”€ plans/                      # Cached plans
â”œâ”€â”€ execution/                      # Execution System
â”‚   â”œâ”€â”€ mcp_client.py               # MCP protocol
â”‚   â””â”€â”€ adaptive_executor.py        # GPT-4o-mini resolution + failure handling
â”œâ”€â”€ feedback/                       # HITL System
â”‚   â”œâ”€â”€ human_observer.py           # Background thread for approvals/feedback
â”‚   â””â”€â”€ schemas.py                  # FailureLearning, TaskVerification
â”œâ”€â”€ learning/                       # Skills Library
â”‚   â”œâ”€â”€ skill_library.py            # Verified workflows storage & matching
â”‚   â””â”€â”€ verified_skills/            # Task-specific skill JSON files
â”œâ”€â”€ prompts/                        # LLM prompts
â”‚   â”œâ”€â”€ planning_prompt.py          # Planning prompts
â”‚   â”œâ”€â”€ kb_recovery_approach_prompt.py  # Recovery generation prompt
â”‚   â””â”€â”€ planning_history/           # Saved prompts for debugging
â””â”€â”€ utils/
    â””â”€â”€ cost_tracker.py             # API cost monitoring
```

---

## ğŸ› ï¸ Setup

### 1. Install Dependencies
```bash
python -m venv .agent-venv
.agent-venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure API Key
```bash
cp .env.example .env
# Edit .env: OPENAI_API_KEY=sk-...
```

### 3. Build Knowledge Base (one-time)
```bash
python agent/knowledge_base/doc_parser.py
python agent/knowledge_base/indexer.py --rebuild
```

### 4. Run
```bash
python agent/workflows/autonomous_workflow.py "Your task here"
```

---

## ğŸ“– Usage Examples

### Basic Usage
```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

result = execute_autonomous_task("Open sample.mf4 and plot first signal")
print(f"Success: {result['success']}")
```

### Handling Failures (Iterative Rerun)
```python
# First attempt - may fail
result = execute_autonomous_task("Concatenate all MF4 files")

if not result['success']:
    print("Learning attached to KB. Rerunning...")
    result = execute_autonomous_task("Concatenate all MF4 files")  # Better plan
```

### Recovery Approach Generation

After successful task completion and skill creation, the system prompts:

```
[KB Update] Would you like to update the knowledge catalog with
            recovery approaches from this verified skill?
Update knowledge catalog? [y/N]: y

[Recovery Generator] Processing 3 KB items with errors needing recovery approaches
[Recovery Generator] Generated 3 recovery approaches
  [Updated] open_files: Added recovery approach
  [Updated] save_file: Added recovery approach
âœ“ Knowledge catalog updated successfully!
```

---

## âš¡ Performance

- **First Run** (no learnings): 70-80% success rate
- **After Learning** (rerun with context): 85-95% success rate
- **Subsequent Similar Tasks**: 95%+ success rate
- **Recovery Generation**: <5s using GPT-4o-mini

---

## ğŸ¯ What Makes This Special

### 1. KB-Attached Learning
- Errors live with the KB items that caused them
- LLM sets `kb_source`, system tracks which patterns fail
- Trust scores decay with failures

### 2. LLM-Generated Recovery Approaches
- **Automated**: Analyzes verified skills after success
- **Contextual**: Reviews entire action sequence for comprehensive understanding
- **Concise**: 2-3 statement max, actionable guidance
- **Cost-effective**: Uses GPT-4o-mini
- **Smart**: Skips LLM call if all errors already have recovery approaches

### 3. Iterative Rerun (Not Automatic)
- User control over reruns
- Deterministic, debuggable flow
- Progressive improvement with each iteration

### 4. Learning Prioritization
- Verified skills > KB learnings > Documentation
- "Learnings trump documentation" - prevents circular failures

---

## ğŸ“ Schemas Reference

### KnowledgeSchema
```python
knowledge_id: str
description: str
action_sequence: List[str]
kb_learnings: List[Dict]  # FailureLearning with recovery_approach
trust_score: float  # 0.5-1.0
```

### FailureLearning (attached to KB items)
```python
task: str
step_num: int
original_action: Dict[str, Any]
original_error: str
recovery_approach: str  # Generated by LLM from verified skills
timestamp: str
```

---

## âš ï¸ Limitations

- **Platform:** Windows-only
- **Scope:** Single application (designed for asammdf)
- **Vision:** Text-based UI state (no GPT-4o vision)
- **Execution:** Sequential (no parallel actions)
- **Learning:** User must explicitly rerun to apply learnings

---

## ğŸ“ˆ Status

**Current Version:** KB-Attached Learning with HITL + Recovery Approach Generation

âœ… **Complete:**
- HITL System (skills, approvals, interactive mode, verification)
- KB-attached learning with trust scores
- Iterative rerun architecture
- **LLM-generated recovery approaches from verified skills**
- Learning prioritization (skills > learnings > docs)
- Cost monitoring

ğŸš§ **Future:**
- Multi-app workflows
- GPT-4o vision for state capture
- Parallel execution

---

**Happy Automating! ğŸš€**


@ -0,0 +1,149 @@
# Parameterized Tasks - Usage Guide

## Overview

The autonomous workflow now uses **parameterized tasks only**. All file/folder paths are separated from the core operation logic, making plans and verified skills reusable across different folders.

---

## Format

**Required:**
- `operation`: Core task description without paths
- `parameters`: JSON object with path parameters

**Standard Parameters:**
- `input_folder`: Folder containing input files
- `output_folder`: Folder for output files
- `output_filename`: Name of output file

---

## Usage

### 1. Run with Default Task

```bash
python agent/workflows/autonomous_workflow.py
```

**Default operation:** "Concatenate all .MF4 files and save with specified name"

**Default parameters:**
```json
{
  "input_folder": "C:\\Users\\ADMIN\\Downloads\\ev-data-pack-v10\\...\\Kia EV6\\LOG\\2F6913DB\\00001026",
  "output_folder": "C:\\Users\\ADMIN\\Downloads\\ev-data-pack-v10\\...\\Kia EV6\\LOG\\2F6913DB",
  "output_filename": "Kia_EV_6_2F6913DB.mf4"
}
```

### 2. Run with Custom Task

```bash
python agent/workflows/autonomous_workflow.py \
  --operation "Concatenate all .MF4 files and save with specified name" \
  --parameters '{"input_folder": "C:\\data\\Tesla_Model_3\\LOG\\00000001", "output_folder": "C:\\output", "output_filename": "Tesla_Model_3.mf4"}'
```

**Note:** On Windows, escape backslashes in JSON: `\\` becomes `\\\\`

### 3. Python API

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

results = execute_autonomous_task(
    operation="Concatenate all .MF4 files and save with specified name",
    parameters={
        "input_folder": r"C:\data\Tesla_Model_3\LOG\00000001",
        "output_folder": r"C:\output",
        "output_filename": "Tesla_Model_3.mf4"
    },
    interactive_mode=True
)

print(f"Success: {results['success']}")
print(f"Steps: {results['steps_completed']}")
```

---

## How It Works

### 1. Task Parsing
System converts operation + parameters to internal format:
```
"Concatenate all .MF4 files and save with specified name (Parameters: input_folder=C:\data\Tesla, output_folder=C:\output, output_filename=Tesla.mf4)"
```

### 2. Planning
GPT generates plan with placeholders:
```json
{
  "tool_name": "Type-Tool",
  "tool_arguments": {
    "text": "{input_folder}",
    "clear": true,
    "press_enter": true
  },
  "reasoning": "Enter input folder path from parameters"
}
```

### 3. Execution
AdaptiveExecutor substitutes placeholders before execution:
- `{input_folder}` â†’ `C:\data\Tesla`
- `{output_folder}` â†’ `C:\output`
- `{output_filename}` â†’ `Tesla.mf4`

### 4. Skill Matching
- **Operation-based**: Matches on core operation only, ignoring paths
- **Reusable**: Same skill works for different folders
- **Example**: Skill for "Concatenate all .MF4 files" matches any folder

---

## Benefits

âœ… **Reusability**: Plans/skills work across different folders
âœ… **Clarity**: Separate logic from data
âœ… **Privacy**: Don't embed specific paths in skills
âœ… **Flexibility**: Change paths without regenerating plans
âœ… **Consistency**: Single standardized format

---

## Example: Reusing Verified Skills

**First run** (Kia EV6):
```bash
python agent/workflows/autonomous_workflow.py \
  --operation "Concatenate all .MF4 files and save with specified name" \
  --parameters '{"input_folder": "C:\\data\\Kia_EV6\\LOG\\00001026", "output_folder": "C:\\output", "output_filename": "Kia.mf4"}'
```
â†’ Creates verified skill with operation "Concatenate all .MF4 files and save with specified name"

**Second run** (Tesla Model 3):
```bash
python agent/workflows/autonomous_workflow.py \
  --operation "Concatenate all .MF4 files and save with specified name" \
  --parameters '{"input_folder": "C:\\data\\Tesla_Model_3\\LOG\\00000001", "output_folder": "C:\\output", "output_filename": "Tesla.mf4"}'
```
â†’ **Matches existing skill!** Reuses proven workflow with new parameters

---

## Troubleshooting

**Q: "operation and parameters must be provided together" error**
A: Both `--operation` and `--parameters` are required. Use both or neither (for default task).

**Q: JSON parsing error**
A: Ensure backslashes are escaped: `"C:\\folder"` not `"C:\folder"`

**Q: Placeholder not substituted**
A: Check placeholder name matches parameter key exactly (case-sensitive)

**Q: Skill not matching**
A: Ensure operation text is similar (>75% similarity threshold)