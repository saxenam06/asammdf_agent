**Autonomous GUI Automation with Iterative Learning** 

- Natural language tasks â†’ GUI control with knowledge base learning, human verification, and skill library.
- ASAMMDF Agent is an autonomous GUI automation system that executes Windows GUI based workflows on ASAMMDF tool from natural-language instructions. Given a task description, it generates UI action plans and executes them using MCP tools (e.g., click, type, key-shortcuts, window focus), while continuously improving by learning from failures and converting successful runs into reusable skills. Each rerun leverages accumulated knowledge, making the automation progressively more reliable and repeatable.
---

## ğŸš€ Quick Start

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

# Execute with parameters
result = execute_autonomous_task(
    operation="Concatenate all .MF4 files and save with specified name",
    parameters={
        "input_folder": r"C:\data\vehicle_logs",
        "output_folder": r"C:\output",
        "output_filename": "concatenated.mf4"
    },
    interactive_mode=True  # Press ESC for step feedback
)

print(f"Success: {result['success']}")
```

**On failure:** Error attached to knowledge base â†’ User reruns with improved context
**On success:** Human verifies â†’ Saved as reusable verified skill

---

## ğŸ”„ Complete Workflow

### One-Time Setup

```
doc_parser.py â†’ Fetch asammdf docs â†’ LLM extracts patterns â†’ knowledge_catalog.json
                                                                        â†“
indexer.py â†’ Embed into ChromaDB vector store (semantic search ready)
```

### Per-Task Execution (6-Node LangGraph State Machine)

```
User: "Concatenate MF4 files" + parameters
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [1] retrieve_knowledge                                          â”‚
â”‚  â€¢ Check verified skills (fuzzy match â‰¥75%)                     â”‚
â”‚  â€¢ If no match â†’ ChromaDB semantic search                       â”‚
â”‚  â€¢ Returns KB items with learnings + trust scores               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [2] generate_plan (GPT-5-mini)                                  â”‚
â”‚  â€¢ LLM receives: task + parameters + KB items with learnings    â”‚
â”‚  â€¢ Sets kb_source for each action (tracks which KB inspired it) â”‚
â”‚  â€¢ Uses {parameter} placeholders for reusability                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [3] validate_plan                                               â”‚
â”‚  â€¢ Human reviews plan (if HITL enabled)                         â”‚
â”‚  â€¢ Collects feedback/modifications                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [4] execute_step (loop for each step)                           â”‚
â”‚  â€¢ Substitute parameters: {input_folder} â†’ actual path          â”‚
â”‚  â€¢ GPT-4o-mini resolves symbolic refs â†’ coordinates             â”‚
â”‚  â€¢ MCP client executes Windows automation                       â”‚
â”‚  â€¢ Interactive: ESC for step feedback                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [5] verify_step                                                 â”‚
â”‚  â€¢ Check execution result                                       â”‚
â”‚  â€¢ If error â†’ [handle_error] â†’ STOP (user must rerun)          â”‚
â”‚  â€¢ If success + more steps â†’ Loop to execute_step              â”‚
â”‚  â€¢ If all done â†’ Continue                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [6] final_verification (HITL)                                   â”‚
â”‚  â€¢ Human verifies task completion                               â”‚
â”‚  â€¢ Save as VerifiedSkill                                        â”‚
â”‚  â€¢ Prompt: Generate recovery approaches for KB?                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error Learning Flow (Iterative Improvement)

```
Step N fails
    â†“
System finds kb_source from failed action
    â†“
Create FailureLearning (task, error, timestamp)
    â†“
Attach to KB item in knowledge_catalog.json
    â†“
Update trust_score: Ã—0.95 (min 0.5)
    â†“
Sync to ChromaDB metadata
    â†“
STOP execution
    â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USER RERUNS SAME TASK
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â†“
Retrieval includes KB item WITH learning
    â†“
GPT-5-mini sees previous error in planning context
    â†“
Generates better plan avoiding past mistakes
    â†“
Success!
```

### Success Flow (Skill Creation)

```
All steps complete successfully
    â†“
Human verification prompt
    â†“
Save VerifiedSkill JSON
  â€¢ operation (path-agnostic)
  â€¢ parameters schema
  â€¢ full action sequence
  â€¢ metadata (success_rate, timestamps)
    â†“
Prompt: "Update KB with recovery approaches? [y/N]"
    â†“
If yes â†’ GPT-4o-mini analyzes verified skill
    â†“
For each KB item that had errors:
  â€¢ Generate recovery_approach (2-3 sentences)
  â€¢ Add to kb_learnings in catalog.json
    â†“
Future tasks benefit from error + recovery context
```

---

## ğŸ—ï¸ Technical Architecture

### Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Knowledge Base** | ChromaDB + sentence-transformers | Semantic pattern retrieval |
| **Planning** | GPT-5-mini | Generate parameterized action plans |
| **Execution** | GPT-4o-mini | Resolve UI symbolic references to coordinates |
| **Automation** | MCP (Model Context Protocol) | Windows GUI control |
| **Recovery Generation** | GPT-4o-mini | Extract learnings from verified skills |
| **Learning Storage** | JSON catalog + ChromaDB metadata | KB-attached error learnings |
| **Skills Library** | JSON per verified task | Reusable workflows with fuzzy matching |
| **Orchestration** | LangGraph | State machine workflow |

### Core Mechanisms

**1. KB-Source Attribution**
- LLM assigns `kb_source` to each action during planning
- When action fails â†’ System knows which KB item caused it
- Learning attached directly to causative pattern (not random)

**2. Parameterized Tasks**
- Operations separate from paths: `"Concatenate files"` + `{"input_folder": "..."}`
- Planner uses `{parameter_name}` placeholders
- Executor substitutes before execution
- Skills reusable across different folders/files

**3. Symbolic Reference Resolution**
- Planner: `"Click button with text 'Open'"`
- Executor: GPT-4o-mini + State-Tool output â†’ Resolves to `(x, y)` coordinates
- Adapts to UI changes dynamically

**4. Trust Score Decay**
- Each failure: `trust_score Ã— 0.95` (minimum 0.5)
- Stored in both `knowledge_catalog.json` and ChromaDB metadata
- Tracks reliability of KB patterns over time

**5. Fuzzy Skill Matching**
- `SequenceMatcher` compares operations (ignoring parameters)
- Threshold: 75% similarity
- Example: "Concatenate MF4 files" matches "Concatenate all .MF4 files"
- Enables skill reuse for similar tasks

**6. Human-in-the-Loop (HITL) Touchpoints**
- **Plan review**: Before execution starts
- **ESC key interrupt**: During execution (interactive mode)
- **Low confidence approval**: When LLM uncertain (future feature)
- **Final verification**: After task completion

### Data Structures

**knowledge_catalog.json** (source of truth):
```json
{
  "knowledge_id": "open_files",
  "description": "Open files using File menu",
  "action_sequence": ["Click File", "Click Open", "..."],
  "kb_learnings": [{
    "task": "Concatenate files",
    "original_error": "Button 'Add Files' not found",
    "recovery_approach": "Use Ctrl+O instead of Add Files button",
    "timestamp": "2025-11-03T10:30:00"
  }],
  "trust_score": 0.95
}
```

**ChromaDB stores**:
- Vector embeddings (from KB description)
- Metadata: full_knowledge (JSON), trust_score, learning_count

**VerifiedSkill JSON** (`agent/learning/verified_skills/`):
```json
{
  "operation": "Concatenate all .MF4 files and save with specified name",
  "parameters": {
    "input_folder": "Path to folder with MF4 files",
    "output_folder": "Path to save output",
    "output_filename": "Name of output file"
  },
  "action_sequence": [{...}, {...}],
  "metadata": {
    "success_rate": 1.0,
    "created_at": "2025-11-03T10:35:00",
    "last_used": "2025-11-03T10:35:00"
  }
}
```

---

## ğŸ’» Setup & Usage

### Installation

```bash
# Create virtual environment
python -m venv .agent-venv
.agent-venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure API key
cp .env.example .env
# Edit .env: OPENAI_API_KEY=sk-...
```

### Build Knowledge Base (One-Time)

```bash
# Parse asammdf documentation
python agent/knowledge_base/doc_parser.py

# Index into ChromaDB
python agent/knowledge_base/indexer.py --rebuild
```

### Python API

**Basic Usage:**
```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

result = execute_autonomous_task(
    operation="Open MF4 file and plot first signal",
    parameters={"file_path": r"C:\data\sample.mf4"}
)
```

**Iterative Rerun (Handling Failures):**
```python
# First attempt - may fail
result = execute_autonomous_task(
    operation="Concatenate all .MF4 files and save with specified name",
    parameters={
        "input_folder": r"C:\data\logs",
        "output_folder": r"C:\output",
        "output_filename": "merged.mf4"
    }
)

# If failed, learning attached to KB
if not result['success']:
    print("Learning attached. Rerunning...")
    result = execute_autonomous_task(
        operation="Concatenate all .MF4 files and save with specified name",
        parameters={
            "input_folder": r"C:\data\logs",
            "output_folder": r"C:\output",
            "output_filename": "merged.mf4"
        }
    )
    # Better plan with learning context
```

**Interactive Mode:**
```python
result = execute_autonomous_task(
    operation="Export signals to CSV",
    parameters={"input_file": r"C:\data\test.mf4"},
    interactive_mode=True  # Press ESC during execution for feedback
)
```

---

## ğŸ“ Project Structure

```
agent/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ autonomous_workflow.py      # LangGraph 6-node orchestrator + HITL
â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ doc_parser.py               # One-time doc processing (GPT-5-mini)
â”‚   â”œâ”€â”€ indexer.py                  # ChromaDB vector indexing
â”‚   â”œâ”€â”€ retriever.py                # Semantic search + fuzzy skill matching
â”‚   â”œâ”€â”€ recovery_approach_generator.py  # LLM-based recovery generation
â”‚   â”œâ”€â”€ parsed_knowledge/
â”‚   â”‚   â””â”€â”€ knowledge_catalog.json  # SOURCE OF TRUTH (learnings + trust scores)
â”‚   â””â”€â”€ vector_store/               # ChromaDB (embeddings + metadata)
â”œâ”€â”€ planning/
â”‚   â”œâ”€â”€ workflow_planner.py         # Plan generation with KB context (GPT-5-mini)
â”‚   â”œâ”€â”€ schemas.py                  # KnowledgeSchema, ActionSchema, PlanSchema
â”‚   â””â”€â”€ plans/                      # Cached plans
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ adaptive_executor.py        # Step execution + error handling + learning attachment
â”‚   â””â”€â”€ mcp_client.py               # Windows MCP automation client
â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ human_observer.py           # HITL interactions (plan review, verification)
â”‚   â””â”€â”€ schemas.py                  # FailureLearning, TaskVerification schemas
â”œâ”€â”€ learning/
â”‚   â”œâ”€â”€ skill_library.py            # Verified skill storage + fuzzy matching
â”‚   â””â”€â”€ verified_skills/            # JSON files per verified task
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ planning_prompt.py          # Planning system prompts
â”‚   â”œâ”€â”€ coordinate_resolution_prompt.py  # UI resolution prompts
â”‚   â”œâ”€â”€ doc_parsing_prompt.py       # Doc extraction prompts
â”‚   â””â”€â”€ kb_recovery_approach_prompt.py   # Recovery generation prompts
â””â”€â”€ utils/
    â”œâ”€â”€ cost_tracker.py             # LLM API cost monitoring
    â””â”€â”€ parameter_substitution.py   # {placeholder} â†’ value substitution
```

---

## âœ¨ Key Features

- **KB-Attached Learning**: Errors stored with patterns that caused them (not random)
- **Verified Skills**: Human-verified workflows with fuzzy matching (â‰¥75% similarity)
- **Parameterized Tasks**: Reusable skills across different files/folders
- **Trust Scores**: KB pattern reliability tracking (0.95Ã— per failure, min 0.5)
- **Recovery Approaches**: LLM analyzes verified skills to generate recovery guidance
- **Interactive Mode**: ESC key for real-time feedback during execution
- **Iterative Improvement**: Rerun with learning context â†’ Progressive success
- **Symbolic Resolution**: Dynamic UI adaptation (text references â†’ coordinates)

---

## ğŸ“ˆ Performance

- **First Run** (no learnings): 70-80% success rate
- **After Learning** (rerun with context): 85-95% success rate
- **Verified Skill Match**: 95%+ success rate (direct reuse)
- **Recovery Generation**: <5 seconds using GPT-4o-mini

---

## âš ï¸ Limitations

- **Platform**: Windows-only (MCP protocol)
- **Scope**: Single application (designed for asammdf)
- **Execution**: Sequential steps (no parallel actions)
- **Learning**: Manual rerun required to apply learnings

---

## ğŸ¯ What Makes This Special

### 1. KB-Source Attribution
Unlike generic RAG systems, the LLM explicitly tracks which KB pattern inspired each action. When actions fail, the system knows exactly which pattern to blame and attach learnings to.

### 2. Iterative Rerun Architecture
No automatic retries or replanning. User explicitly reruns tasks, system provides progressively better context. Simple, debuggable, and user-controlled.

### 3. LLM-Generated Recovery Approaches
After successful task completion, GPT-4o-mini analyzes the verified skill to generate concise recovery guidance for KB items that had errors. Future tasks benefit from both error history and recovery strategies.

### 4. Parameterized Task Separation
Operations separated from data: `"Concatenate files"` + `{"input_folder": "..."}`. Same skill works for different folders. Privacy-friendly (no paths embedded in skills).

---

**Happy Automating! ğŸš€**
