# asammdf Agent

**Autonomous GUI Automation Agent** - Natural language â†’ GUI control with self-healing and human-in-the-loop learning.

---

## ğŸš€ Quick Start

```python
from agent.workflows.autonomous_workflow import AutonomousWorkflow

# HITL enabled by default
workflow = AutonomousWorkflow()
result = workflow.run_sync("Concatenate all MF4 files in C:\\data and save as output.mf4")
```

**Interactive:** Press Ctrl+I anytime to interrupt and provide corrections.

---

## ğŸ“‹ Table of Contents

- [System Architecture](#system-architecture)
- [Core Tech Stack](#core-tech-stack)
- [Key Features](#key-features)
- [Folder Structure](#folder-structure)
- [How It Works](#how-it-works)
- [HITL Features](#hitl-features)
- [Setup](#setup)
- [Usage Examples](#usage-examples)
- [Performance](#performance)
- [Dependencies](#dependencies)
- [Contributing](#contributing)

---

## ğŸ—ï¸ System Architecture

### 5-Phase Autonomous Pipeline

```
Natural Language Task â†’ RAG Retrieval â†’ AI Planning â†’ Adaptive Execution â†’ Auto-Recovery
                              â†“              â†“              â†“              â†“
                         ChromaDB       GPT-5-mini     GPT-4o-mini    Replanning
```

**1. RAG Retrieval** - ChromaDB semantic search over documentation (<1s)
**2. AI Planning** - GPT-5-mini generates MCP tool sequences (2-5s)
**3. Adaptive Execution** - GPT-4o-mini resolves UI elements dynamically (~500ms/element)
**4. Auto-Recovery** - Detects failures, replans with KB context (3-8s)
**5. Orchestration** - LangGraph state machine with bounded retry/replan

---

## ğŸ’» Core Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Knowledge Base** | ChromaDB + sentence-transformers | Semantic doc search |
| **Planning** | GPT-5-mini (OpenAI) | MCP tool sequence generation |
| **Execution** | GPT-4o-mini (OpenAI) | Dynamic UI resolution |
| **Recovery** | Plan tracking + replanning | KB-augmented recovery |
| **Orchestration** | LangGraph | State machine (retry/replan) |
| **MCP Tools** | Windows-MCP server | 13+ GUI automation tools |
| **HITL Learning** | Mem0 + JSON | Multi-source learning storage |
| **Skill Library** | TF-IDF matching | Verified workflow reuse |

---

## âœ¨ Key Features

### Autonomous System
âœ… **Documentation-driven** - No hardcoded actions (GPT extracts from docs)
âœ… **Adaptive** - Resolves UI elements dynamically, finds alternatives
âœ… **Self-healing** - Auto-replans on failures (3 attempts max)
âœ… **State-aware** - Caches UI state for coordinate resolution
âœ… **Versioned plans** - Incremental merge (`Plan_0`, `Plan_1`, ...)
âœ… **Cost tracking** - Real-time API monitoring by component/model

### HITL System (Optional, enabled by default)
âœ… **Skill library** - Reuses verified workflows (skip planning)
âœ… **Memory retrieval** - Learns from human corrections + self-recovery
âœ… **Confidence-based approval** - Requests approval for low confidence (<0.5)
âœ… **Procedural guidance** - Teach multi-step workflows with context
âœ… **Human interrupts** - Press Ctrl+I anytime for corrections
âœ… **Progressive autonomy** - Less intervention needed over time
âœ… **Audit trail** - Complete communication logs

---

## ğŸ“ Folder Structure

```
agent/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ autonomous_workflow.py      # LangGraph orchestrator (6 nodes)
â”œâ”€â”€ knowledge_base/                 # RAG System
â”‚   â”œâ”€â”€ doc_parser.py               # Parse documentation with GPT
â”‚   â”œâ”€â”€ indexer.py                  # Index into ChromaDB
â”‚   â”œâ”€â”€ retriever.py                # Semantic search
â”‚   â”œâ”€â”€ parsed_knowledge/           # Extracted knowledge (JSON)
â”‚   â””â”€â”€ vector_store/               # ChromaDB vector database
â”œâ”€â”€ planning/                       # Planning System
â”‚   â”œâ”€â”€ workflow_planner.py         # GPT-5-mini planning
â”‚   â”œâ”€â”€ plan_recovery.py            # KB-augmented replanning
â”‚   â”œâ”€â”€ schemas.py                  # Pydantic models
â”‚   â””â”€â”€ plans/                      # Cached plans
â”œâ”€â”€ execution/                      # Execution System
â”‚   â”œâ”€â”€ mcp_client.py               # MCP protocol (async)
â”‚   â””â”€â”€ adaptive_executor.py        # GPT-4o-mini UI resolution
â”œâ”€â”€ feedback/                       # HITL System
â”‚   â”œâ”€â”€ communication_protocol.py   # A2A-inspired messaging
â”‚   â”œâ”€â”€ schemas.py                  # Learning types
â”‚   â”œâ”€â”€ memory_manager.py           # Mem0-powered storage
â”‚   â””â”€â”€ human_observer.py           # Interactive CLI
â”œâ”€â”€ learning/
â”‚   â””â”€â”€ skill_library.py            # Verified skill matching
â”œâ”€â”€ prompts/                        # Centralized LLM prompts
â”‚   â”œâ”€â”€ planning_prompt.py
â”‚   â”œâ”€â”€ recovery_prompt.py
â”‚   â”œâ”€â”€ coordinate_resolution_prompt.py
â”‚   â””â”€â”€ doc_parsing_prompt.py
â””â”€â”€ utils/
    â””â”€â”€ cost_tracker.py             # API cost monitoring
```

---

## ğŸ”„ How It Works

### Example: "Concatenate MF4 files in C:\data"

#### Phase 1: RAG Retrieval (<1s)
```
Query â†’ ChromaDB â†’ Top-5 patterns: concatenate_files, open_folder, save_file
```

#### Phase 2: HITL Planning (2-5s or instant)
```
Check SkillLibrary â†’ Found verified skill (similarity: 0.85)?
  YES â†’ Use skill's plan (instant, skip LLM)
  NO  â†’ Retrieve learnings â†’ Generate plan with GPT-5-mini
```

#### Phase 3: Adaptive Execution (~500ms/element)
```
State-Tool â†’ Cache UI
Click-Tool {"loc": ["last_state:menu:File"]} â†’ GPT resolves â†’ [120, 30] â†’ Click
... execution continues ...
Step 15: Low confidence (0.4) â†’ Request human approval
```

#### Phase 4: Auto-Recovery (if failure, 3-8s)
```
Failure detected â†’ Save snapshot â†’ Summarize progress
â†’ KB query: "concatenate button" â†’ 3 patterns
â†’ GPT generates recovery plan (10 steps)
â†’ Merge: 14 completed + 10 new = 24 total
â†’ Resume execution
```

#### Phase 5: Final Verification (HITL)
```
All steps completed â†’ Request human verification
Human approves â†’ Create verified skill in library
Next time: Instant execution with verified skill!
```

---

## ğŸ¤ HITL Features

### Confidence-Based Approval

When agent confidence is low (<0.5), you get 5 options:

```
==================================================================
  HUMAN APPROVAL NEEDED (Step 8)
==================================================================
Agent Confidence: 0.35 (LOW)

Proposed Action:
  Tool: Click-Tool
  Arguments: {"loc": [500, 300]}
  Reasoning: Looking for 'Add Files' button

------------------------------------------------------------------
Options:
  [1] Approve - Execute as proposed
  [2] Reject - Provide quick correction
  [3] Skip - Skip this step
  [4] Guidance - Provide general guidance
  [5] Detailed Procedure - Provide step-by-step instructions
------------------------------------------------------------------

Your choice [1-5]:
```

### Procedural Guidance (Option 5)

Teach the agent complete multi-step workflows:

```
What is the goal of this procedure?
Goal: Add MF4 files to concatenate list

Provide step-by-step instructions (one per line).
Type 'DONE' when finished.

Step 1: Click on File menu in menu bar
Step 2: Click Open option
Step 3: Navigate to folder containing MF4 files
Step 4: Click on any MF4 file
Step 5: Press Ctrl+A to select all files
Step 6: Press Enter to load all files
Step 7: DONE

Any key points to remember?
Key points: Ctrl+A selects all files, Files must be in same folder

Common mistakes to avoid?
Mistakes: Don't look for 'Add Files' button - it doesn't exist

Alternative ways to achieve the same goal?
Alternatives: Can drag and drop from File Explorer
```

**Benefits:**
- âœ… Teach complex procedures once, reused forever
- âœ… Document institutional knowledge automatically
- âœ… Prevent repeated mistakes
- âœ… Provide multiple alternative approaches

### Progressive Autonomy

| Run | Human Interventions | Success Rate | Time | Notes |
|-----|-------------------|--------------|------|-------|
| 1st | 3-5 corrections | 70-80% | 5-10 min | Learning phase |
| 2nd-3rd | 1-2 corrections | 85-90% | 3-5 min | Improvement phase |
| 4th+ | 0 corrections | 95-98% | <1 min | Uses verified skill |

**First run:** No skills â†’ Plan from scratch â†’ Human corrections â†’ Verify â†’ Create skill
**Subsequent runs:** Found skill (0.7+ similarity) â†’ Use verified plan â†’ Fast execution

---

## ğŸ› ï¸ Setup

### 1. Install Dependencies

```bash
# Create virtual environment
python -m venv .agent-venv
.agent-venv\Scripts\activate
pip install -r requirements.txt

# Install Windows-MCP tools
cd tools\Windows-MCP
python -m venv .windows-venv
.windows-venv\Scripts\activate
pip install -e .
cd ..\..
```

### 2. Configure API Key

```bash
cp .env.example .env
# Edit .env: OPENAI_API_KEY=sk-...
```

### 3. Extract Knowledge (one-time)

```bash
# Parse documentation
python agent/knowledge_base/doc_parser.py

# Build index
python agent/knowledge_base/indexer.py --rebuild
```

### 4. Run

```bash
python agent/workflows/autonomous_workflow.py "Your task here"
```

---

## ğŸ“– Usage Examples

### Basic Usage

```python
from agent.workflows.autonomous_workflow import execute_autonomous_task

# HITL enabled by default
result = execute_autonomous_task("Open sample.mf4 and plot first signal")
print(f"Success: {result['success']}")
```

### Without HITL (Fully Autonomous)

```python
from agent.workflows.autonomous_workflow import AutonomousWorkflow

workflow = AutonomousWorkflow(enable_hitl=False)
result = workflow.run_sync("Your task")
```

### Custom Configuration

```python
workflow = AutonomousWorkflow(
    app_name="asammdf 8.6.10",
    catalog_path="agent/knowledge_base/parsed_knowledge/knowledge_catalog.json",
    vector_db_path="agent/knowledge_base/vector_store",
    max_retries=2,
    max_replan_attempts=3,
    enable_hitl=True,
    session_id="user_john_001"  # Track learnings per user
)
result = workflow.run_sync("Your task")
```

### Cost Tracking

```python
from agent.utils.cost_tracker import get_global_tracker

tracker = get_global_tracker()
tracker.print_summary()  # Component/model breakdown
tracker.save_to_file()   # Export to cost_reports/
```

### Inspect Learnings

```python
from agent.feedback.memory_manager import LearningMemoryManager

memory = LearningMemoryManager()
learnings = memory.retrieve_all_learnings_for_task(
    task="Concatenate MF4 files",
    session_id="your_session"
)
print(f"Human guidance: {len(learnings['human_proactive'])}")
print(f"Corrections: {len(learnings['human_interrupt'])}")
print(f"Self-recovery: {len(learnings['agent_self_exploration'])}")
```

### Inspect Verified Skills

```python
from agent.learning.skill_library import SkillLibrary

library = SkillLibrary()
for skill_id, skill in library.skills.items():
    print(f"Task: {skill.original_task}")
    print(f"Success: {skill.success_rate:.1%}")
    print(f"Used: {skill.usage_count} times")
```

### Knowledge Base Operations

```python
from agent.knowledge_base import KnowledgeRetriever

# Semantic search
retriever = KnowledgeRetriever()
results = retriever.retrieve("concatenate MF4 files", top_k=5)

for pattern in results:
    print(f"{pattern.knowledge_id}: {pattern.description}")
```

---

## âš¡ Performance

### Without HITL
- Knowledge retrieval: <1s
- Plan generation: 2-5s
- Element resolution: ~500ms
- Total: 10-60s (task-dependent)
- Success rate: 70-80%

### With HITL (First Run)
- Planning: 2-5s (or instant if skill found)
- Human interactions: 3-5 approvals
- Total: 5-10 min
- Success rate: 95% (with corrections)

### With HITL (Subsequent Runs)
- Planning: <1s (skill reuse)
- Human interactions: 0-1 approvals
- Total: <1 min
- Success rate: 98%

---

## ğŸ“¦ Dependencies

### Core
```bash
pip install chromadb sentence-transformers  # RAG
pip install openai                          # LLM
pip install langgraph langchain             # Orchestration
pip install pydantic                        # Type safety
pip install nest-asyncio                    # Async handling
pip install requests beautifulsoup4 lxml   # Doc parsing
```

### HITL (Optional but recommended)
```bash
pip install mem0ai          # Learning memory
pip install scikit-learn    # Skill matching
```

### Windows MCP Tools
```bash
cd tools/Windows-MCP
pip install -e .
```

---

## ğŸ¯ What Makes This Special

### Technical Innovations
1. **Documentation-Driven** - GPT extracts all knowledge from docs (no hardcoding)
2. **Adaptive Resolution** - GPT interprets intent, finds UI alternatives dynamically
3. **Self-Healing** - Auto-replans with KB context on failures
4. **Progressive Autonomy** - Learns from corrections, builds skill library
5. **Incremental Planning** - Merges completed work with recovery plans

### HITL Innovations
6. **Multi-Source Learning** - Human proactive + interrupts + agent self-recovery
7. **Skill Reuse** - Fuzzy matching (70%+ similarity) skips planning entirely
8. **Confidence-Based** - Only asks for approval when uncertain
9. **Procedural Guidance** - Teach complete workflows with context
10. **Mem0 Integration** - Semantic search with JSON fallback (works offline)
11. **A2A-Inspired Protocol** - Structured communication with audit trail

---

## ğŸ“Š Data Storage

### HITL Memory (Mem0 + JSON Fallback)
```
agent/feedback/memory/
â”œâ”€â”€ sessions/              # JSON backup (always)
â”‚   â””â”€â”€ session_xyz.json
â””â”€â”€ qdrant_db/             # Mem0 vector store (if OpenAI key available)
```

### Verified Skills
```
agent/learning/
â””â”€â”€ skill_library.json     # Fuzzy-matched verified workflows
```

### Cached Plans
```
agent/planning/plans/
â”œâ”€â”€ Task1_hash_Plan_0.json
â”œâ”€â”€ Task1_hash_Plan_1.json
â””â”€â”€ Task2_hash_Plan_0.json
```

### Audit Trail
```
agent/feedback/message_logs/
â””â”€â”€ session_xyz_messages.json  # Complete communication history
```

---

## âš ï¸ Limitations

- **Platform:** Windows-only (Windows UI Automation)
- **Scope:** Single application (designed for asammdf, extensible)
- **Vision:** Text-based UI state (can add GPT-4o vision)
- **Execution:** Sequential (no parallel actions)

---

## ğŸ“ Interactive Commands (HITL)

**Press Ctrl+I** - Interrupt execution anytime
- Provide corrections
- Skip steps
- Stop execution

**Low Confidence Actions** - Auto-prompted
- Agent asks for approval before uncertain actions (<0.5 confidence)
- You can approve, correct, skip, provide guidance, or teach procedures

**Final Verification** - After completion
- Verify task success
- Provide feedback
- Creates verified skill if approved

---

## ğŸ¤ Contributing

See inline documentation and module-level docstrings. Key design principles:

1. **Centralized prompts** - Easy A/B testing (all in `agent/prompts/`)
2. **Type safety** - Pydantic everywhere for data validation
3. **Graceful degradation** - Fallbacks for all external dependencies
4. **Complete audit trail** - All interactions logged
5. **Progressive autonomy** - Less human input over time
6. **Modular architecture** - Each component has single responsibility

---

## ğŸ“ˆ Status

**Core System:** âœ… Production-ready
- Complete agentic loop (learn â†’ plan â†’ execute â†’ recover)
- Documentation-driven (no hardcoding)
- Self-healing (KB-augmented replanning)
- Production error handling

**HITL System:** âœ… Complete (10/10 components)
- Bidirectional feedback
- Multi-source learning
- Verified skill library
- Procedural guidance
- Progressive autonomy
- Full audit trail

**Knowledge Base:** âœ… Reorganized
- Separated parsing, indexing, and retrieval
- Clean module structure with CLI tools
- Model-agnostic naming

**Result:** Natural language â†’ GUI automation with self-healing, human collaboration, and continuous learning.

---

## ğŸš§ Future Enhancements

**Phase 1 (Complete):**
- âœ… Multi-source learning system
- âœ… Verified skill library
- âœ… Interactive human feedback
- âœ… Procedural guidance feature
- âœ… Knowledge base reorganization

**Phase 2 (Optional):**
- Multi-app workflows
- GPT-4o vision integration
- Parallel execution
- Team collaboration (Langfuse)
- Safety guidelines (Parlant)

---

## ğŸ“ License

[Specify your license here]

---

## ğŸ“§ Contact

[Specify contact information here]

---

**Happy Automating! ğŸš€**

For questions or issues, please refer to:
- Code documentation (inline comments and docstrings)
- Component READMEs in respective folders
- GitHub issues (if applicable)
