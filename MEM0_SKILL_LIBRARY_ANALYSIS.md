# Mem0-Based Skill Library Analysis

## Current Implementation: SequenceMatcher (difflib)

### How It Works:
```python
def similarity_score(self, task: str) -> float:
    """Character-level string matching"""
    return SequenceMatcher(None, self.task_description.lower(), task.lower()).ratio()
```

### Example Matching:
```
Task 1: "Concatenate MF4 files in folder C:\data"
Task 2: "Concatenate MF4 files in folder C:\logs"
Similarity: 0.92 (92% character match)

Task 1: "Concatenate MF4 files in folder C:\data"
Task 3: "Merge MDF files in directory C:\data"
Similarity: 0.48 (48% character match) ‚ùå Won't match at 0.7 threshold
```

### Strengths ‚úÖ
- **Fast**: O(n) operation, no external API calls
- **Deterministic**: Same input = same output
- **No dependencies**: Pure Python stdlib
- **Works offline**: No internet required
- **Zero cost**: No API usage

### Weaknesses ‚ùå
- **Literal matching**: "Concatenate" vs "Merge" = poor match (semantically identical!)
- **Path sensitivity**: Different folder paths drastically reduce similarity
- **No semantic understanding**: Doesn't understand task intent
- **Brittle**: Small wording changes break matching
- **No generalization**: Can't match conceptually similar tasks

---

## Proposed: Mem0-Based Skill Library

### How It Would Work:

```python
class Mem0SkillLibrary:
    """Semantic skill matching using Mem0's vector embeddings"""

    def __init__(self):
        from mem0 import Memory
        self.memory = Memory()
        self.skills_json = "agent/learning/verified_skills/skills.json"

    def add_skill(
        self,
        skill_id: str,
        task_description: str,
        action_plan: List[ActionSchema],
        metadata: VerifiedSkillMetadata,
        tags: List[str]
    ):
        """Store skill in Mem0 with semantic embeddings"""

        # Format skill as rich text for embeddings
        skill_text = f"""
Verified Skill: {task_description}

Action Plan ({len(action_plan)} steps):
{self._format_action_plan(action_plan)}

Tags: {', '.join(tags)}
Success Rate: {metadata.success_rate:.1%}
Times Used: {metadata.times_used}
"""

        # Store in Mem0 with metadata
        self.memory.add(
            messages=[{"role": "assistant", "content": skill_text}],
            user_id="skill_library",  # Single user for all skills
            metadata={
                "skill_id": skill_id,
                "task_description": task_description,
                "tags": tags,
                "success_rate": metadata.success_rate,
                "times_used": metadata.times_used,
                "created_at": metadata.verified_at
            }
        )

        # Also save to JSON for backup
        self._save_to_json(skill_id, task_description, action_plan, metadata, tags)

    def find_similar_skills(
        self,
        task: str,
        threshold: float = 0.7,
        min_success_rate: float = 0.8,
        limit: int = 3
    ) -> List[VerifiedSkill]:
        """Find semantically similar skills"""

        # Search Mem0 with semantic similarity
        results = self.memory.search(
            query=task,
            user_id="skill_library",
            limit=limit
        )

        # Filter by success rate and convert to VerifiedSkill objects
        skills = []
        for result in results.get('results', []):
            metadata = result.get('metadata', {})

            # Check success rate filter
            if metadata.get('success_rate', 0) < min_success_rate:
                continue

            # Mem0 returns relevance score (0-1)
            similarity = result.get('score', 0)

            if similarity >= threshold:
                # Load full skill from JSON
                skill_id = metadata['skill_id']
                skill = self._load_from_json(skill_id)
                if skill:
                    skill.similarity_score = similarity  # Attach score
                    skills.append(skill)

        return skills
```

### Example Matching:
```
Task 1: "Concatenate MF4 files in folder C:\data"
Stored Skill: "Merge MF4 files in directory C:\logs"

SequenceMatcher: 0.48 ‚ùå (below 0.7 threshold)
Mem0 Semantic:   0.89 ‚úÖ (recognizes "merge" = "concatenate", "folder" = "directory")
```

```
Task 2: "Combine all measurement files in the Tesla folder"
Stored Skill: "Concatenate MF4 files in folder C:\data"

SequenceMatcher: 0.22 ‚ùå (completely different words)
Mem0 Semantic:   0.82 ‚úÖ (understands semantic similarity!)
```

### Strengths ‚úÖ
- **Semantic understanding**: Matches "concatenate" = "merge" = "combine"
- **Path agnostic**: Different folders still match if task is same
- **Generalization**: "measurement files" matches "MF4 files"
- **Robust to paraphrasing**: Intent-based matching
- **Metadata filtering**: Can filter by tags, success rate, recency
- **Multi-language support**: Could work with non-English tasks

### Weaknesses ‚ùå
- **API dependency**: Requires OpenAI API (costs money)
- **Slower**: Network call + embedding generation (~200-500ms)
- **Non-deterministic**: Slight variations in scores across calls
- **Requires internet**: Won't work offline (unless using local embeddings)
- **Complexity**: More moving parts, harder to debug

---

## Comparison Matrix

| Feature | SequenceMatcher | Mem0 Semantic |
|---------|----------------|---------------|
| **Speed** | üü¢ Instant (<1ms) | üü° Fast (~200ms) |
| **Accuracy** | üî¥ Literal only | üü¢ Semantic understanding |
| **Offline** | üü¢ Yes | üî¥ No (requires API) |
| **Cost** | üü¢ Free | üü° ~$0.0001 per query |
| **Paraphrase handling** | üî¥ Poor | üü¢ Excellent |
| **Path sensitivity** | üî¥ Very sensitive | üü¢ Robust |
| **Synonym matching** | üî¥ None | üü¢ Excellent |
| **Debugging** | üü¢ Easy | üü° Harder |
| **Dependencies** | üü¢ Stdlib only | üî¥ mem0ai, OpenAI |

---

## Recommended Solution: **Hybrid Approach** üéØ

### Why Hybrid?

1. **Fast path**: Try SequenceMatcher first (instant, free)
2. **Semantic fallback**: Use Mem0 if no literal match found
3. **Best of both worlds**: Speed + accuracy

### Implementation:

```python
class HybridSkillLibrary:
    """Hybrid skill library with literal + semantic matching"""

    def __init__(
        self,
        library_path: str = "agent/learning/verified_skills/skills.json",
        use_semantic: bool = True
    ):
        """
        Initialize hybrid library

        Args:
            library_path: Path to JSON skill storage
            use_semantic: Enable Mem0 semantic search (requires API key)
        """
        self.library_path = library_path
        self.skills: List[VerifiedSkill] = []

        # Always load JSON skills
        self.load()

        # Optionally initialize Mem0
        self.use_semantic = use_semantic
        self.memory = None
        if use_semantic:
            try:
                from mem0 import Memory
                self.memory = Memory()
                print("[SkillLibrary] Semantic matching enabled (Mem0)")
            except Exception as e:
                print(f"[Warning] Mem0 not available, using literal matching only: {e}")
                self.use_semantic = False

    def find_similar_skills(
        self,
        task: str,
        threshold: float = 0.7,
        min_success_rate: float = 0.8,
        limit: int = 3
    ) -> List[VerifiedSkill]:
        """
        Find similar skills using hybrid approach

        Strategy:
        1. Try literal matching (SequenceMatcher) - fast, free
        2. If no matches, try semantic matching (Mem0) - slower, accurate

        Args:
            task: Task description
            threshold: Minimum similarity (0.0-1.0)
            min_success_rate: Minimum skill success rate
            limit: Max results

        Returns:
            List of matching skills sorted by similarity
        """
        # STEP 1: Try literal matching first (fast path)
        literal_matches = self._find_literal_matches(
            task, threshold, min_success_rate, limit
        )

        if literal_matches:
            print(f"[SkillLibrary] Found {len(literal_matches)} literal matches")
            return literal_matches

        # STEP 2: Fallback to semantic matching
        if self.use_semantic and self.memory:
            print("[SkillLibrary] No literal matches, trying semantic search...")
            semantic_matches = self._find_semantic_matches(
                task, threshold, min_success_rate, limit
            )

            if semantic_matches:
                print(f"[SkillLibrary] Found {len(semantic_matches)} semantic matches")
                return semantic_matches

        print("[SkillLibrary] No matching skills found")
        return []

    def _find_literal_matches(
        self,
        task: str,
        threshold: float,
        min_success_rate: float,
        limit: int
    ) -> List[VerifiedSkill]:
        """Literal string matching (current implementation)"""
        candidates = []

        for skill in self.skills:
            # Calculate character-level similarity
            similarity = SequenceMatcher(
                None,
                skill.task_description.lower(),
                task.lower()
            ).ratio()

            # Filter by thresholds
            if (similarity >= threshold and
                skill.metadata.success_rate >= min_success_rate):
                skill.similarity_score = similarity  # Attach score
                candidates.append(skill)

        # Sort by similarity and return top N
        candidates.sort(key=lambda x: x.similarity_score, reverse=True)
        return candidates[:limit]

    def _find_semantic_matches(
        self,
        task: str,
        threshold: float,
        min_success_rate: float,
        limit: int
    ) -> List[VerifiedSkill]:
        """Semantic matching using Mem0"""
        if not self.memory:
            return []

        try:
            # Search Mem0
            results = self.memory.search(
                query=task,
                user_id="skill_library",
                limit=limit * 2  # Get more candidates for filtering
            )

            # Convert to VerifiedSkill objects
            matches = []
            for result in results.get('results', []):
                metadata = result.get('metadata', {})

                # Check filters
                success_rate = metadata.get('success_rate', 0)
                similarity = result.get('score', 0)

                if success_rate >= min_success_rate and similarity >= threshold:
                    skill_id = metadata.get('skill_id')

                    # Find skill in loaded skills
                    skill = next(
                        (s for s in self.skills if s.skill_id == skill_id),
                        None
                    )

                    if skill:
                        skill.similarity_score = similarity
                        matches.append(skill)

            # Sort and limit
            matches.sort(key=lambda x: x.similarity_score, reverse=True)
            return matches[:limit]

        except Exception as e:
            print(f"[Warning] Semantic search failed: {e}")
            return []

    def add_skill(
        self,
        task_description: str,
        action_plan: List[ActionSchema],
        session_id: str,
        human_feedbacks_count: int = 0,
        agent_recoveries_count: int = 0,
        tags: Optional[List[str]] = None
    ) -> VerifiedSkill:
        """
        Add verified skill to both JSON and Mem0

        Args:
            task_description: Task description
            action_plan: Proven action sequence
            session_id: Session where verified
            human_feedbacks_count: Human corrections used
            agent_recoveries_count: Agent self-recoveries
            tags: Categorization tags

        Returns:
            Created VerifiedSkill
        """
        # Generate skill ID
        skill_id = f"skill_{len(self.skills) + 1:03d}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # Create metadata
        metadata = VerifiedSkillMetadata(
            session_id=session_id,
            human_feedbacks_count=human_feedbacks_count,
            agent_recoveries_count=agent_recoveries_count
        )

        # Create skill
        skill = VerifiedSkill(
            skill_id=skill_id,
            task_description=task_description,
            action_plan=action_plan,
            metadata=metadata,
            tags=tags or []
        )

        # Add to in-memory list
        self.skills.append(skill)

        # Save to JSON (always)
        self.save()

        # Index in Mem0 (if available)
        if self.use_semantic and self.memory:
            try:
                self._index_skill_in_mem0(skill)
            except Exception as e:
                print(f"[Warning] Failed to index in Mem0: {e}")

        print(f"[SkillLibrary] Added verified skill: {skill_id}")
        return skill

    def _index_skill_in_mem0(self, skill: VerifiedSkill):
        """Index a skill in Mem0 for semantic search"""
        # Format skill as rich description
        skill_text = f"""
Task: {skill.task_description}

Workflow ({len(skill.action_plan)} steps):
"""
        for i, action in enumerate(skill.action_plan, 1):
            skill_text += f"{i}. {action.tool_name}: {action.reasoning}\n"

        if skill.tags:
            skill_text += f"\nTags: {', '.join(skill.tags)}"

        # Store in Mem0
        self.memory.add(
            messages=[{"role": "assistant", "content": skill_text}],
            user_id="skill_library",
            metadata={
                "skill_id": skill.skill_id,
                "task_description": skill.task_description,
                "tags": skill.tags,
                "success_rate": skill.metadata.success_rate,
                "times_used": skill.metadata.times_used,
                "created_at": skill.metadata.verified_at
            }
        )

    # ... rest of methods (save, load, etc.) remain the same
```

---

## Usage Example

```python
# Initialize with semantic matching enabled
library = HybridSkillLibrary(use_semantic=True)

# Add a verified skill
library.add_skill(
    task_description="Concatenate MF4 files in folder C:\\data",
    action_plan=[...],
    session_id="session_001",
    tags=["mf4", "concatenate", "file_ops"]
)

# Query 1: Literal match (instant)
matches = library.find_similar_skills("Concatenate MF4 files in folder C:\\logs")
# Result: Found via SequenceMatcher (fast path)

# Query 2: Semantic match (needs Mem0)
matches = library.find_similar_skills("Merge measurement files in Tesla directory")
# Result: No literal match ‚Üí Mem0 semantic search ‚Üí Found!

# Query 3: Offline mode (semantic disabled)
library_offline = HybridSkillLibrary(use_semantic=False)
matches = library_offline.find_similar_skills("Combine MF4 files")
# Result: Only literal matching available
```

---

## Cost Analysis

### Mem0 API Costs:
- Embedding generation: ~$0.0001 per query
- Storage: Free (first 1000 memories)
- Expected usage: ~10-50 queries/day = $0.001-0.005/day

### Performance Impact:
- Literal match: <1ms
- Semantic match: ~200-500ms (only when literal fails)
- 90%+ of queries use fast path

---

## Recommendation: **Hybrid Approach** ‚úÖ

### Implementation Plan:

1. **Keep current SequenceMatcher** (fast path)
2. **Add Mem0 semantic fallback** (optional, configurable)
3. **Graceful degradation**: Works offline without Mem0

### Benefits:
- ‚úÖ Best of both worlds (speed + accuracy)
- ‚úÖ No breaking changes
- ‚úÖ Works offline (falls back to literal)
- ‚úÖ Minimal cost (only uses Mem0 when needed)
- ‚úÖ Better matching for paraphrased tasks

### Trade-offs:
- ‚ö†Ô∏è Slightly more complex code
- ‚ö†Ô∏è Small API cost when semantic search used
- ‚ö†Ô∏è Additional dependency (mem0ai)

---

## Next Steps

1. **Implement `HybridSkillLibrary`** in `agent/learning/skill_library.py`
2. **Add `use_semantic` parameter** to `AutonomousWorkflow.__init__()`
3. **Test with real tasks** to measure improvement
4. **Monitor costs** and adjust thresholds
5. **Collect metrics**: literal match rate vs semantic match rate

Would you like me to implement the hybrid approach?
